{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.datasets import make_classification\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split, GridSearchCV\n", "from sklearn.metrics import precision_recall_fscore_support"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_samples = 10000\n", "num_classes = 2\n", "weights = [0.95, 0.05]\n", "num_features = 3\n", "n_informative = 2\n", "n_repeated = 0\n", "n_redundant = 0\n", "test_size_second_split = 0.90"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["seed = 202204"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = make_classification(\n", "    n_samples=num_samples,\n", "    n_classes=num_classes,\n", "    weights=weights,\n", "    n_features=num_features,\n", "    n_informative=n_informative,\n", "    n_redundant=n_redundant,\n", "    n_repeated=n_repeated,\n", "    random_state=seed,\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.bar([\"class 0\", \"class 1\"], pd.Series(y).value_counts().to_list())\n", "ax.set_title(\"Distribution of data across classes\")\n", "fig.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.2, stratify=y, shuffle=True, random_state=seed\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure()\n", "titles = [\n", "    f\"{dataset}: Distribution of data across classes\"\n", "    for dataset in [\"Train set\", \"Test set\"]\n", "]\n", "for i, target in enumerate([y_train, y_test]):\n", "    ax = plt.subplot(2, 1, i + 1)\n", "    ax.bar([\"class 0\", \"class 1\"], pd.Series(target).value_counts().to_list())\n", "    ax.set_title(titles[i])\n", "fig.tight_layout()\n", "fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_simple_random_sample, _, y_train_simple_random_sample, _ = train_test_split(\n", "    X_train, y_train, test_size=test_size_second_split, shuffle=True, random_state=seed\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_stratified_sample, _, y_train_stratified_sample, _ = train_test_split(\n", "    X_train,\n", "    y_train,\n", "    test_size=test_size_second_split,\n", "    stratify=y_train,\n", "    shuffle=True,\n", "    random_state=seed,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Model hyperparams"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["C = np.logspace(0, 4, 10)\n", "penalty = [\"l1\", \"l2\"]\n", "hyperparams = dict(C=C, penalty=penalty)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lr = LogisticRegression(solver=\"liblinear\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gridsearch = GridSearchCV(lr, hyperparams, cv=5, verbose=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Case 1:<br>\n", "grid-search CV on train_simple_random_sample, and evaluate on _test<br>\n", "plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.bar(\n", "    [\"class 0\", \"class 1\"],\n", "    pd.Series(y_train_simple_random_sample).value_counts().to_list(),\n", ")\n", "ax.set_title(\"Simple random sample: Distribution of data across classes\")\n", "fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["CV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_model_01 = gridsearch.fit(\n", "    X_train_simple_random_sample, y_train_simple_random_sample\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_penalty = best_model_01.best_estimator_.get_params()[\"penalty\"]\n", "best_C = best_model_01.best_estimator_.get_params()[\"C\"]\n", "best_acc_score = best_model_01.best_estimator_.score(\n", "    X_train_simple_random_sample, y_train_simple_random_sample\n", ")\n", "best_acc_score_test = best_model_01.best_estimator_.score(X_test, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred_01 = best_model_01.best_estimator_.predict(X_test)\n", "best_results = precision_recall_fscore_support(y_test, y_pred_01, average=\"binary\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('')\n", "# print(f'Simple random sampling: Best accuracy score on train data: {best_acc_score}')\n", "# print(f'Simple random sampling: Best accuracy score on test data: {best_acc_score_test}')  # noqa\n", "# print(f'Simple random sampling: Best accuracy precision, recall, f1: {best_results}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Case 2:<br>\n", "grid-search CV on train_simple_random_sample, and evaluate on _test<br>\n", "plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.bar(\n", "    [\"class 0\", \"class 1\"],\n", "    pd.Series(y_train_stratified_sample).value_counts().to_list(),\n", ")\n", "ax.set_title(\"Stratified sample: Distribution of data across classes\")\n", "fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["CV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_model_02 = gridsearch.fit(X_train_stratified_sample, y_train_stratified_sample)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_penalty_02 = best_model_02.best_estimator_.get_params()[\"penalty\"]\n", "best_C_02 = best_model_02.best_estimator_.get_params()[\"C\"]\n", "best_acc_score_02 = best_model_02.best_estimator_.score(\n", "    X_train_stratified_sample, y_train_stratified_sample\n", ")\n", "best_acc_score_test_02 = best_model_02.best_estimator_.score(X_test, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred_02 = best_model_02.best_estimator_.predict(X_test)\n", "best_results_02 = precision_recall_fscore_support(y_test, y_pred_02, average=\"binary\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Summary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"X.shape:       {X.shape}\")\n", "print(f\"X_train.shape: {X_train.shape}\")\n", "print(f\"X_train_simple_random_sample.shape: {X_train_simple_random_sample.shape}\")\n", "print(f\"X_train_stratified_sample.shape:    {X_train_stratified_sample.shape}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print(f'Coefs from simple random sampling: {best_model_01.best_estimator_.coef_}')<br>\n", "print(f'Coefs from stratified sampling:    {best_model_02.best_estimator_.coef_}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Simple random sampling: Best accuracy score on train data: {best_acc_score}\")\n", "print(f\"Simple random sampling: Best accuracy score on test data:{best_acc_score_test}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Stratified sampling: Best accuracy score on train data:{best_acc_score_02}\")\n", "print(f\"Stratified sampling: Best accuracy score on test data:{best_acc_score_test_02}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Simple random sampling: Best precision, recall, f1: {best_results}\")\n", "print(f\"Stratified sampling: Best precision, recall, f1:    {best_results_02}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}