{"metadata":{"jupytext":{"cell_metadata_filter":"-all","formats":"ipynb"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction #\n\nMost of the techniques we've seen in this course have been for numerical features. The technique we'll look at in this lesson, *target encoding*, is instead meant for categorical features. It's a method of encoding categories as numbers, like one-hot or label encoding, with the difference that it also uses the *target* to create the encoding. This makes it what we call a **supervised** feature engineering technique.","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\n\nautos = pd.read_csv(\"../input/fe-course-data/autos.csv\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-08-01T18:43:28.052769Z","iopub.execute_input":"2024-08-01T18:43:28.053787Z","iopub.status.idle":"2024-08-01T18:43:28.407691Z","shell.execute_reply.started":"2024-08-01T18:43:28.053743Z","shell.execute_reply":"2024-08-01T18:43:28.406836Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"autos.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T18:43:29.797623Z","iopub.execute_input":"2024-08-01T18:43:29.798001Z","iopub.status.idle":"2024-08-01T18:43:29.837916Z","shell.execute_reply.started":"2024-08-01T18:43:29.797974Z","shell.execute_reply":"2024-08-01T18:43:29.836931Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   symboling         make fuel_type aspiration  num_of_doors   body_style  \\\n0          3  alfa-romero       gas        std             2  convertible   \n1          3  alfa-romero       gas        std             2  convertible   \n2          1  alfa-romero       gas        std             2    hatchback   \n3          2         audi       gas        std             4        sedan   \n4          2         audi       gas        std             4        sedan   \n\n  drive_wheels engine_location  wheel_base  length  ...  engine_size  \\\n0          rwd           front        88.6   168.8  ...          130   \n1          rwd           front        88.6   168.8  ...          130   \n2          rwd           front        94.5   171.2  ...          152   \n3          fwd           front        99.8   176.6  ...          109   \n4          4wd           front        99.4   176.6  ...          136   \n\n   fuel_system  bore stroke  compression_ratio  horsepower peak_rpm  city_mpg  \\\n0         mpfi  3.47   2.68                  9         111     5000        21   \n1         mpfi  3.47   2.68                  9         111     5000        21   \n2         mpfi  2.68   3.47                  9         154     5000        19   \n3         mpfi  3.19   3.40                 10         102     5500        24   \n4         mpfi  3.19   3.40                  8         115     5500        18   \n\n   highway_mpg  price  \n0           27  13495  \n1           27  16500  \n2           26  16500  \n3           30  13950  \n4           22  17450  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>symboling</th>\n      <th>make</th>\n      <th>fuel_type</th>\n      <th>aspiration</th>\n      <th>num_of_doors</th>\n      <th>body_style</th>\n      <th>drive_wheels</th>\n      <th>engine_location</th>\n      <th>wheel_base</th>\n      <th>length</th>\n      <th>...</th>\n      <th>engine_size</th>\n      <th>fuel_system</th>\n      <th>bore</th>\n      <th>stroke</th>\n      <th>compression_ratio</th>\n      <th>horsepower</th>\n      <th>peak_rpm</th>\n      <th>city_mpg</th>\n      <th>highway_mpg</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>alfa-romero</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>2</td>\n      <td>convertible</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>88.6</td>\n      <td>168.8</td>\n      <td>...</td>\n      <td>130</td>\n      <td>mpfi</td>\n      <td>3.47</td>\n      <td>2.68</td>\n      <td>9</td>\n      <td>111</td>\n      <td>5000</td>\n      <td>21</td>\n      <td>27</td>\n      <td>13495</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>alfa-romero</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>2</td>\n      <td>convertible</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>88.6</td>\n      <td>168.8</td>\n      <td>...</td>\n      <td>130</td>\n      <td>mpfi</td>\n      <td>3.47</td>\n      <td>2.68</td>\n      <td>9</td>\n      <td>111</td>\n      <td>5000</td>\n      <td>21</td>\n      <td>27</td>\n      <td>16500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>alfa-romero</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>2</td>\n      <td>hatchback</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>94.5</td>\n      <td>171.2</td>\n      <td>...</td>\n      <td>152</td>\n      <td>mpfi</td>\n      <td>2.68</td>\n      <td>3.47</td>\n      <td>9</td>\n      <td>154</td>\n      <td>5000</td>\n      <td>19</td>\n      <td>26</td>\n      <td>16500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>audi</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>4</td>\n      <td>sedan</td>\n      <td>fwd</td>\n      <td>front</td>\n      <td>99.8</td>\n      <td>176.6</td>\n      <td>...</td>\n      <td>109</td>\n      <td>mpfi</td>\n      <td>3.19</td>\n      <td>3.40</td>\n      <td>10</td>\n      <td>102</td>\n      <td>5500</td>\n      <td>24</td>\n      <td>30</td>\n      <td>13950</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>audi</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>4</td>\n      <td>sedan</td>\n      <td>4wd</td>\n      <td>front</td>\n      <td>99.4</td>\n      <td>176.6</td>\n      <td>...</td>\n      <td>136</td>\n      <td>mpfi</td>\n      <td>3.19</td>\n      <td>3.40</td>\n      <td>8</td>\n      <td>115</td>\n      <td>5500</td>\n      <td>18</td>\n      <td>22</td>\n      <td>17450</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"autos.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T15:00:12.768274Z","iopub.execute_input":"2024-07-31T15:00:12.769383Z","iopub.status.idle":"2024-07-31T15:00:12.785618Z","shell.execute_reply.started":"2024-07-31T15:00:12.769338Z","shell.execute_reply":"2024-07-31T15:00:12.783704Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 193 entries, 0 to 192\nData columns (total 25 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   symboling          193 non-null    int64  \n 1   make               193 non-null    object \n 2   fuel_type          193 non-null    object \n 3   aspiration         193 non-null    object \n 4   num_of_doors       193 non-null    int64  \n 5   body_style         193 non-null    object \n 6   drive_wheels       193 non-null    object \n 7   engine_location    193 non-null    object \n 8   wheel_base         193 non-null    float64\n 9   length             193 non-null    float64\n 10  width              193 non-null    float64\n 11  height             193 non-null    float64\n 12  curb_weight        193 non-null    int64  \n 13  engine_type        193 non-null    object \n 14  num_of_cylinders   193 non-null    int64  \n 15  engine_size        193 non-null    int64  \n 16  fuel_system        193 non-null    object \n 17  bore               193 non-null    float64\n 18  stroke             193 non-null    float64\n 19  compression_ratio  193 non-null    int64  \n 20  horsepower         193 non-null    int64  \n 21  peak_rpm           193 non-null    int64  \n 22  city_mpg           193 non-null    int64  \n 23  highway_mpg        193 non-null    int64  \n 24  price              193 non-null    int64  \ndtypes: float64(6), int64(11), object(8)\nmemory usage: 37.8+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Target Encoding #\n\nA **target encoding** is any kind of encoding that replaces a feature's categories with some number derived from the target.\n\nA simple and effective version is to apply a group aggregation from Lesson 3, like the mean. Using the *Automobiles* dataset, this computes the average price of each vehicle's make:","metadata":{"lines_to_next_cell":0}},{"cell_type":"code","source":"autos.groupby('make')['price'].nunique().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T18:45:17.968688Z","iopub.execute_input":"2024-08-01T18:45:17.969076Z","iopub.status.idle":"2024-08-01T18:45:17.979070Z","shell.execute_reply.started":"2024-08-01T18:45:17.969047Z","shell.execute_reply":"2024-08-01T18:45:17.978080Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"make\ntoyota           31\nnissan           17\nsubaru           12\nmazda            12\nmitsubishi       12\nhonda            12\nvolkswagen       12\npeugot           11\nvolvo            11\ndodge             8\nbmw               8\nmercedes-benz     8\nplymouth          7\naudi              6\nsaab              6\nporsche           4\njaguar            3\nchevrolet         3\nalfa-romero       2\nisuzu             2\nmercury           1\nName: price, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"autos.query('make == \"toyota\"')[['make', 'price']].head()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T18:45:53.965273Z","iopub.execute_input":"2024-08-01T18:45:53.965689Z","iopub.status.idle":"2024-08-01T18:45:53.987473Z","shell.execute_reply.started":"2024-08-01T18:45:53.965651Z","shell.execute_reply":"2024-08-01T18:45:53.986188Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       make  price\n138  toyota   5348\n139  toyota   6338\n140  toyota   6488\n141  toyota   6918\n142  toyota   7898","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>make</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>138</th>\n      <td>toyota</td>\n      <td>5348</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>toyota</td>\n      <td>6338</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>toyota</td>\n      <td>6488</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>toyota</td>\n      <td>6918</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>toyota</td>\n      <td>7898</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"autos[\"make_encoded\"] = autos.groupby(\"make\")[\"price\"].transform(\"mean\")\n\nautos[[\"make\", \"price\", \"make_encoded\"]].query('make == \"toyota\"')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T18:48:01.771601Z","iopub.execute_input":"2024-08-01T18:48:01.772719Z","iopub.status.idle":"2024-08-01T18:48:01.791387Z","shell.execute_reply.started":"2024-08-01T18:48:01.772681Z","shell.execute_reply":"2024-08-01T18:48:01.790188Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"       make  price  make_encoded\n138  toyota   5348     9885.8125\n139  toyota   6338     9885.8125\n140  toyota   6488     9885.8125\n141  toyota   6918     9885.8125\n142  toyota   7898     9885.8125\n143  toyota   8778     9885.8125\n144  toyota   6938     9885.8125\n145  toyota   7198     9885.8125\n146  toyota   7898     9885.8125\n147  toyota   7788     9885.8125\n148  toyota   7738     9885.8125\n149  toyota   8358     9885.8125\n150  toyota   9258     9885.8125\n151  toyota   8058     9885.8125\n152  toyota   8238     9885.8125\n153  toyota   9298     9885.8125\n154  toyota   9538     9885.8125\n155  toyota   8449     9885.8125\n156  toyota   9639     9885.8125\n157  toyota   9989     9885.8125\n158  toyota  11199     9885.8125\n159  toyota  11549     9885.8125\n160  toyota  17669     9885.8125\n161  toyota   8948     9885.8125\n162  toyota  10698     9885.8125\n163  toyota   9988     9885.8125\n164  toyota  10898     9885.8125\n165  toyota  11248     9885.8125\n166  toyota  16558     9885.8125\n167  toyota  15998     9885.8125\n168  toyota  15690     9885.8125\n169  toyota  15750     9885.8125","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>make</th>\n      <th>price</th>\n      <th>make_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>138</th>\n      <td>toyota</td>\n      <td>5348</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>toyota</td>\n      <td>6338</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>toyota</td>\n      <td>6488</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>toyota</td>\n      <td>6918</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>toyota</td>\n      <td>7898</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>toyota</td>\n      <td>8778</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>toyota</td>\n      <td>6938</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>toyota</td>\n      <td>7198</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>toyota</td>\n      <td>7898</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>toyota</td>\n      <td>7788</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>toyota</td>\n      <td>7738</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>toyota</td>\n      <td>8358</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>toyota</td>\n      <td>9258</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>toyota</td>\n      <td>8058</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>toyota</td>\n      <td>8238</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>toyota</td>\n      <td>9298</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>toyota</td>\n      <td>9538</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>toyota</td>\n      <td>8449</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>toyota</td>\n      <td>9639</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>toyota</td>\n      <td>9989</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>toyota</td>\n      <td>11199</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>toyota</td>\n      <td>11549</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>toyota</td>\n      <td>17669</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>toyota</td>\n      <td>8948</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>toyota</td>\n      <td>10698</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>toyota</td>\n      <td>9988</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>toyota</td>\n      <td>10898</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>toyota</td>\n      <td>11248</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>toyota</td>\n      <td>16558</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>toyota</td>\n      <td>15998</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>toyota</td>\n      <td>15690</td>\n      <td>9885.8125</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>toyota</td>\n      <td>15750</td>\n      <td>9885.8125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This kind of target encoding is sometimes called a **mean encoding**. Applied to a binary target, it's also called **bin counting**. (Other names you might come across include: likelihood encoding, impact encoding, and leave-one-out encoding.)\n\n# Smoothing #\n\nAn encoding like this presents a couple of problems, however. First are *unknown categories*. Target encodings create a special risk of overfitting, which means they need to be trained on an independent \"encoding\" split. When you join the encoding to future splits, Pandas will fill in missing values for any categories not present in the encoding split. These missing values you would have to impute somehow.\n\nSecond are *rare categories*. When a category only occurs a few times in the dataset, any statistics calculated on its group are unlikely to be very accurate. In the *Automobiles* dataset, the `mercurcy` make only occurs once. The \"mean\" price we calculated is just the price of that one vehicle, which might not be very representative of any Mercuries we might see in the future. Target encoding rare categories can make overfitting more likely.\n\nA solution to these problems is to add **smoothing**. The idea is to blend the *in-category* average with the *overall* average. Rare categories get less weight on their category average, while missing categories just get the overall average.\n\nIn pseudocode:\n```\nencoding = weight * in_category + (1 - weight) * overall\n```\nwhere `weight` is a value between 0 and 1 calculated from the category frequency.\n\nAn easy way to determine the value for `weight` is to compute an **m-estimate**:\n```\nweight = n / (n + m)\n```\nwhere `n` is the total number of times that category occurs in the data. The parameter `m` determines the \"smoothing factor\". Larger values of `m` put more weight on the overall estimate.\n\n<figure style=\"padding: 1em;\">\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/1uVtQEz.png\" width=500, alt=\"\">\n<figcaption style=\"textalign: center; font-style: italic\"><center>\n</center></figcaption>\n</figure>\n\nIn the *Automobiles* dataset there are three cars with the make `chevrolet`. If you chose `m=2.0`, then the `chevrolet` category would be encoded with 60% of the average Chevrolet price plus 40% of the overall average price.\n```\nchevrolet = 0.6 * 6000.00 + 0.4 * 13285.03\n```\n\nWhen choosing a value for `m`, consider how noisy you expect the categories to be. Does the price of a vehicle vary a great deal within each make? Would you need a lot of data to get good estimates? If so, it could be better to choose a larger value for `m`; if the average price for each make were relatively stable, a smaller value could be okay.\n\n<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n<strong>Use Cases for Target Encoding</strong><br>\nTarget encoding is great for:\n<ul>\n<li><strong>High-cardinality features</strong>: A feature with a large number of categories can be troublesome to encode: a one-hot encoding would generate too many features and alternatives, like a label encoding, might not be appropriate for that feature. A target encoding derives numbers for the categories using the feature's most important property: its relationship with the target.\n<li><strong>Domain-motivated features</strong>: From prior experience, you might suspect that a categorical feature should be important even if it scored poorly with a feature metric. A target encoding can help reveal a feature's true informativeness.\n</ul>\n</blockquote>\n\n# Example - MovieLens1M #\n\nThe [*MovieLens1M*](https://www.kaggle.com/grouplens/movielens-20m-dataset) dataset contains one-million movie ratings by users of the MovieLens website, with features describing each user and movie. This hidden cell sets everything up:","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nwarnings.filterwarnings('ignore')\n\n\ndf = pd.read_csv(\"../input/fe-course-data/movielens1m.csv\")\ndf = df.astype(np.uint8, errors='ignore') # reduce memory footprint\nprint(\"Number of Unique Zipcodes: {}\".format(df[\"Zipcode\"].nunique()))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With over 3000 categories, the `Zipcode` feature makes a good candidate for target encoding, and the size of this dataset (over one-million rows) means we can spare some data to create the encoding.\n\nWe'll start by creating a 25% split to train the target encoder.","metadata":{}},{"cell_type":"code","source":"X = df.copy()\ny = X.pop('Rating')\n\nX_encode = X.sample(frac=0.25)\ny_encode = y[X_encode.index]\nX_pretrain = X.drop(X_encode.index)\ny_train = y[X_pretrain.index]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `category_encoders` package in `scikit-learn-contrib` implements an m-estimate encoder, which we'll use to encode our `Zipcode` feature.","metadata":{}},{"cell_type":"code","source":"from category_encoders import MEstimateEncoder\n\n# Create the encoder instance. Choose m to control noise.\nencoder = MEstimateEncoder(cols=[\"Zipcode\"], m=5.0)\n\n# Fit the encoder on the encoding split.\nencoder.fit(X_encode, y_encode)\n\n# Encode the Zipcode column to create the final training data\nX_train = encoder.transform(X_pretrain)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's compare the encoded values to the target to see how informative our encoding might be.","metadata":{}},{"cell_type":"code","source":"plt.figure(dpi=90)\nax = sns.distplot(y, kde=False, norm_hist=True)\nax = sns.kdeplot(X_train.Zipcode, color='r', ax=ax)\nax.set_xlabel(\"Rating\")\nax.legend(labels=['Zipcode', 'Rating']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of the encoded `Zipcode` feature roughly follows the distribution of the actual ratings, meaning that movie-watchers differed enough in their ratings from zipcode to zipcode that our target encoding was able to capture useful information.\n\n# Your Turn #\n\n[**Apply target encoding**](https://www.kaggle.com/kernels/fork/14393917) to features in *Ames* and investigate a surprising way that target encoding can lead to overfitting.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/feature-engineering/discussion) to chat with other learners.*","metadata":{}}]}